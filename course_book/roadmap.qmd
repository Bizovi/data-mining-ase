---
format:
  html:
    toc-location: left
---

## A map for the adventure

| ![picasso](01_fundamentals/img/safari.svg){width="80%"}| ![big picture](01_fundamentals/img/meme-causal.jpeg){width="80%"}|
|:--:|:--:|
| **[Module I](#module-i-business-context-and-probability):** Business Context and Probability Fundamentals[^r1] | **[Module II](#module-iia-bayesian-statistics):** Applied Bayesian Statistics and Causal Inference

[^r1]: These fundamentals are not "just theory", it is what will make or break our project in practice. We will achieve a lot with simple, elegant models and learn the importance of asking the right questions, persuasive communication, and storytelling.


[We will see that formulating a hypothesis is an art in itself, and that experiment design in practice is fascinating and complicated, full of pitfalls and dangers. That's not your stats 101!]{.aside}


| ![picasso](01_fundamentals/img/umap.png)| ![big picture](01_fundamentals/img/LE_pyeco1.svg){width="100%"}|
|:--:|:--:|
| **[Module III](#module-iii-ml-and-deep-learning):** ML and Deep Learning | **[Projects](#module-iv-full-stack-data-apps):** Software Engineering and Full-Stack Data Apps




We start the course with a first module, in which we explore the [context of data science](01_fundamentals/background.qmd) in businesses, figure out what does AI mean, and where is it useful. Then, we review important statistical concepts and tools, exapting/repurposing them for our objectives, while remembering why they were invented in the first place.






::: {.callout-tip}
## Go to "Resources" page for practice!

Conceptual understanding by itself is not enough. So, I curated a [list of resources](references.qmd) to practice on interesting case-studies, datasets, which directly apply the models, tools, and methodologies presented. These are written by experts in the field, are usually well thought, easy to follow, reproducible, and highlight important aspects of a problem and model.

Also, keep an eye on the course [github repo](https://github.com/Bizovi/decision-making), in which we'll do some exciting projects (full stack data apps) and investigate common problems/challenges with a fresh perspective.
:::

Next, we move on to experiment design and A/B testing. Once you get a taste of decisions with high stakes, we switch to a predictive, Machine Learning perspective and walk through our workhorse models, which should serve us decades ahead in a wide range of applications: both predictive and exploratory.


Did you get comfortable with ML? Good, because it's time to acknowledge the limitations and get more powerful tools from causal inference, when A/B tests and randomised experiments are unfeasible or unethical, but we can leverage naturally-occuring experiments. This is truly challenging: it is an art and science, in contrast with the auto-magic pattern recognition of ML. It requires deep thinking and understanding.

::: {.column-margin}
This is how we jump through various buckets, highlighting the golden thread linking them all: decisions and uncertainty.
:::

The icing on the cake is miscellaneous topics dear to me and usually not covered in such a course: Demand Forecasting, Recommender Systems, and Natural Language Processing. All extremely useful in business contexts, but significant tweaks are needed to the models discussed before.


If you ask what is that engineering branch, you're totally right! During the labs we'll build from the ground up a tech stack for reproducible data analysis, model and data pipelines, culminating in a full-stack data app (with user interface, backend, database), which solves a real-world problem.

That is your final project for the course and something you can brag about in your portfolio and github profile. It sounds complicated, but we have the tools to make it easy for us. Don't worry about getting everything right, but focus on a problem and single area from the course you're passionate about: be it data visualization, ML, statistics or sheer engineering curiosity.


## Module I: Business Context and Probability

::: {.column-page-inset-right}
```{mermaid}
%%| label: fig-mermaid
%%| fig-width: 9
%%| fig-cap: |
%%|   The first module is putting the rest of the course on a solid foundation, emphasizing again and again the key idea of Decision-Making Under Uncertainty at Scale.

flowchart LR
  Prob(Probability) --> Boot(Inference) -- LLN --> Es(Estimators)  --> PS(Stat process)
  Prob -->  Cond(DAGs) -- Cond-g -->  Bayes(Bayes Rule)

  DSc(Decisions, AI) -- statistics  --> Prob(Probability)
  DSc -- business  --> VUCA[V.U.C.A.] --> App(Applications) --> R[Role in firms] 


  R --> BAW(Analyst's Workflow)

  DSc -- method. --> A[Analytics] --- Caus[Causal Inference] --- ML[Learning from Data]
  ML --> PML(ML Process)

  App --> NV(Newsvendor) --> Proj(Projects Overview)

```

:::

The first 4 topics are covered in detail [here](https://course.economic-cybernetics.com/01_fundamentals/background.html) and the [course homepage](https://course.economic-cybernetics.com) gives additional context. The latter 3 are discussed extensively if you follow the links.

- Data Science examples of **Business Applications** - be able to explain most common use-cases in multiple industries, like e-commerce, finance, banking, and medicine.
- **VUCA**, **SWOT** and **Business Strategy** - articulate some properties of the business environment, understand firm's trajectory and how it could translate into a business strategy. Make sure you understand what a strategy is and how it influences our modeling process.
- What is **AI, Data Science, Cybernetics** - understand that, in a nutshell, it's about decision-making under uncertainty at scale, in a given domain of expertise.
- **Analytics** vs **Stats** vs **ML** - be able to match a particular problem with one (or a combination) of these approaches to data-driven problem solving. Know when NOT to use one.
- What is **Machine Learning**? Understand the idea of inductive reasoning, generalization, and be able to 'draw'/outline the core mechanism of the machine learning.  Give examples when it can go wrong or awry. If you have time, refer to [this](https://work.caltech.edu/lectures.html) course, lecture 1 and 2.
- **Newsvendor problem** - understand this demand planning model in business terms and translate it into a mathematical model. Refer to [this tutorial](https://youtu.be/QLsSPnwWS_M).
	- Reason about the role and sources of uncertainty in the decisions and how can we do a stochastic optimization. 
	- Articulate and formalize the trade-offs we're facing. 
	- What happens if the goods are not perishable, what kind of costs we will suffer then?
	- What are some different modeling options for the demand. What kind of distributions will be appropriate for slow-moving, fast-moving, intermittent demand.
- **Price optimization** (fixed capacity) - Give some examples of when it happens in practice. Same questions and concerns as in the newsvendor problem apply. Refer to [this tutorial](https://youtu.be/RScjq1mkDc0) by Dr. Adam Fleischhacker.



### Statistical fundamentals

This is the most difficult part of the course, going into the depths of statistical foundations. Even though you encountered most of these topics in the introductory statistics courses, it is very easy to misunderstand and apply these methods mechanically. 

Therefore, fundamental -- doesn't mean easy, nor basic nor trivial. The exams I give never ask you to compute or solve puzzles, but to appropriately define, justify and apply these (choices) in the context of business applications.

- How does linear algebra, probability, statistics, mathematical analysis, operations research, and economics contribute to Data Science and decision-making? Explained [here](01_fundamentals/prerequisites.qmd)
- Difference between probability theory and mathematical statistics - [a beautiful explanation](https://johnkerl.org/doc/prbstat/prbstat.html)


### The processes of data science

All too often we jump into data analysis and modeling without formulating well the objectives and the problem. Focusing on how to implement and use a model  without following a rigorous process can be error-prone and counterproductive. You have to understand these 3 processes and think how would you structure your project in practice for a particular application.

- [12 Steps of ML](https://medium.com/swlh/12-steps-to-applied-ai-2fdad7fdcdf3) by Cassie Kozyrkov, CRISP-DM (any resource on the latter will do).
- [12 Steps of Statistics](https://youtu.be/R4ckbZCgmxQ) by Cassie Kozyrkov, along with her Google [lecture](https://www.youtube.com/playlist?list=PLRKtJ4IpxJpBxX2S9wXJUhB1_ha3ADFpF) on statistical thinking.
- [Business Analyst's Workflow](https://www.causact.com/becoming-a-data-driven-business-analyst.html#becoming-a-data-driven-business-analyst) by Dr. Adam Fleischhacker


## Module IIa: Bayesian Statistics


::: {.column-page-inset-right}

```{mermaid}
%%| label: fig-mermaid
%%| fig-width: 9
%%| fig-cap: |
%%|   We develop a composable toolbox, capable to tackle the challenges of nonlinearity, heterogeneity, low level of aggregation, discreteness, missing data and heteroskedasticity. By putting together the right pieces in a right way, we can improve predictions and decisions in most aspects of a business. 

flowchart TD
  DM(Decisions)
  DM --> BB(Beta-Bin*) --> GPo(Gamma-Pois*) --> NIG(IG-Norm) --> G(Groups)
  BB --> LR(Logistic Regr.)
  DM --> LM(Linear Regr.) --> GLM(GLMs)  --> Caus(Hierarchical Models) --> Misc[/Time Series/]
  LR --> GLM
  GPo --> GLM
  G <--> Caus

  LM --> P(Prior Choice) --> Reg(Regularization) --> VS(Variable Selection)
  LM --> MS(Model Selection) --> LOO(LOO-PIT)
  LM --> Rb(Robustness) --> NA(Missing Data) --> Surv(Survival and Censoring)
  LM -- nonlinear --> NL(Splines) --> BART(BART) --> GP(Gaussian Proc.)

  DM --> DA(Decision Theory) --> NV(Newsvendor pb.)
  DA --> CF(Classification)
```

:::

## Module IIb: A/B Testing and Causal Inference


## Module III: ML and Deep Learning


::: {.column-page-inset-right}

```{mermaid}
%%| label: fig-mermaid
%%| fig-width: 9
%%| fig-cap: |
%%|   In this ML/DL module, we focus on practical, challenging use-cases and reliable, workhorse methods -- while keeping in mind the particularities of the domain and applications. 

flowchart LR

  DSc --> Unsup(Dim. Reduction) --> Clust(Clustering) --> MM(Mixtures) --> HDB(HDBScan)
  Unsup --> PCA --> CA --> UMAP

  DSc --> Cl(Classification) --> T(Tree-based Models) --> BG(Bagging) --> XG(Boosting)

  Cl --> Im(Imbalance) --> F(Fraud Detection)

  DSc(Decisions, Scale) --> Text[/NLP/] --> EM[Embeddings] --> Attn[Attention] --> ABSA[ABSA]
  DSc --> RS[/RecSys/] --> Mtr[Metrics] --> FM[Factorization Mach.] --> HM[Hybrid Models]
  DSc --> CV(DL: Vision) --> Conv[CNNs] --> AK[Approx. kNN]

  Conv --> HM

  DSc --> TS(Time Series) --> MTS[Metrics] --> XGB[ML Approaches] --> DL[DL Approaches]
  EM --> HM

```

:::


## Module IV: Full-Stack Data Apps


::: {.column-page-inset-right}

```{mermaid}
%%| label: fig-mermaid
%%| fig-width: 9
%%| fig-cap: |
%%|   We will need to learn a lot of engineering and new tools, so that we're able to collect, clean, explore, visualize data, train models, and build useful applications which improve outcomes for our clients.

flowchart LR
  DSc(Data Apps)  --> Data(Data Wrangling)  --> EDA(EDA) --> DV(Visualization)
  EDA --> LP(Literate Programming)
  
  DSc --> Repr[Reproducibility] --> DP[Data Pipelines]
  DSc --> M[Modeling] --> Pymc(PyMC) --> Tr[Torch]
  DSc --> MLP[ML Pipes] --> Srv(Serving Models)
  
  DV --> FS[/Full Stack Apps/]
  Tr --> FS
  Srv --> FS

  Repr --> LP
  DP --> FS
  FS --> Dep[Deploy]
```

:::


## Past Course Syllabus

The in-person and online courses I hold are usually slow-paced and filled with conversations. There is a tremenous ground to cover, especially when the prerequisites are shaky for the methods used. The sections of the book do not correspond with past courses: what reads well might not lead to a good lecture.

While I work on writing and publishing my ideal set of lectures, case-studies, and projects -- which in all honesty might take years, I will leave you an example of a course I held last year, which had a primary focus on statistics, reproducible research, experiment design, and A/B testing.

::: {.column-page-inset-right}

| Course/Lab  | Title                      | Keywords  | Case Studies |
|---------------|-----------------------|-------------------|---------------|
| C1 (09 Dec) | Data Science in Context. Motivation + Roadmap | AI, ML, Uncertainty, Decisions  | discussion of applications|
| C2 (09 Dec) | Why did you study all of that? Course philosophy| Calculus, Linear Algebra, Probability, Stats, Econ | survey of interest and skills  |
| S1 (10 Dec) | Business Analyst's Workflow. Newsvendor Problem | action, outcome, strategy, expertise, data, models, simulation, DAGs | TIME INC. printing/quantity decisions |
| S2 (10 Dec) | Strategy & Desired Trajectory | SWOT, Systems Dynamics, KPIs, Stock vs Flow | LRB Journal Subscriptions |
| C3 (15 Dec) | Newsvendor Problem. Probability distributions. Stochastic Processes  | model specification, inference, simulation, optimization, constraints | groceries and perisable goods |
| C4 (15 Dec) | Probability Triple. Random Variables. Mathematical Statistics | population, sample, r.v., estimators, mixtures, markov chain | Retail Fashion - appropriate choice of distributions  |
| C5 (16 Dec) | Pricing Decisions. Bayesian Inference. Link functions | demand elasticity, fixed capacity, Bayes, revenue management, DAGs  | VIP Lounge at Festivals |
| C6 (16 Dec) | Bayesian Workflow. Regression, what is GLM | prior, likelihood, stochastic optimization  | Flight price optimization (static) |
| S3 (17 Dec) | The most dangerous equation | estimators properties, CLT, sample size | U.S. small schools and top SAT Scores |
| S4 (17 Dec) | Reproducible Research | automation, code, data, environment, documents, publishing | Replication crisis, Excel and the Dead Salmon |
| S5 (17 Dec) | Set Up the Environment. Overview of Data. Version the Code  | Command Line, R, RStudio, Renv, Python, JupyterLab, Quarto, github, RStudio, kaggle | Tooling choice and DevExperience impact on productivity |
| S6 (17 Dec) | Tidyverse warm-up | dplyr, ggplot2, quarto, renv projects, rendering | Tiny Sleep dataset tidy data wrangling  |
| Winter Break | \*** | \*** | \***  |
| C7 (12 Jan) | 12 Steps of ML. What is ML?  | PAC Learning, generalization, CRISP-DM | Project requirements simplification |
| C8 (12 Jan) | 12 Steps of Statistics. A/B Testing Scheme | Default Action, Stat. Hypotheses, confidence intervals, relevance | problem of p-value |
| C9 (13 Jan) | A/B Testing pitfalls | A/A Tests, Selection bias, Confounders, Novelty | The need for rigorous experiments |
| C10 (13 Jan) | Error Types, Effect Size, p-values | tests for difference in proportions and means | Strategy for simulation |
| S7 (14 Jan) | Self-practice: tidyverse data wrangling | \*** | Movie Data |
| S8 (14 Jan) | Self-practice: ggplot data visualization | \*** | Covid infections, Geographical data |
| S9 (14 Jan) | Power, Sample Size calculations, Non-inferiority tests | relevance, minimal effect size | Neyman-Pearson, frequentism as action in the long-term |
| S10 (14 Jan) | Self-practice: Linear regression review | Hypothesis tests as linear models | Guidance with student projects |
| C11 (19 Jan) | Properties of Metrics for A/B Testing | Sensitivity, stability, directedness | Potential pitfalls |
| C12 (19 Jan) | Properties of Estimators | Bias-Variance, Fisher Information, Rao-Cramer | Relevance for ML, Deep Learning |
| C13 (20 Jan) | LLN, CLT, Asymptotics and Exact Criteria | $\chi^2_k, N, F_{m, n}, t_k$ | Delta method  |
| C14 (20 Jan) | Bootstrap and Nonparametrics | resampling, ECDF |  Kolmogorov-Smirnov |
| S11 (21 Jan) | CLT, Choosing a test, Trading off errors, Increasing Power. What next? | Cohen's d, PPV, GLM, nonparametrics, multilevel models | Justifying $\alpha, 1 - \beta, \Delta, n$ by simulation |
| S12 (21 Jan) | Likelihood, Regularization | Likelihood ratio, James-Stein, curse of dimensionality | Getting a taste of the Fisherian perspective |
| S13 (21 Jan) | Bayesian inference | Priors, Bayes Factors, Credible intervals | Generative models, Model critique |
| S14 (21 Jan) | Bootstrap, Multiple Testing | FDR, Bonferoni | Computer-age statistical inference |

:::
