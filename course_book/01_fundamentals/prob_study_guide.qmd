
# Probability and Statistics: Study Guide

Many mistakes in statistical modeling and inference come from a misunderstanding about the nature of statistical inference. This is why we start from the very beginning, with counting. But first, read the [motivation](../index.qmd#module-2-probability-and-statistics) from course introduction.

::: {.column-margin}

In contrast with the previous module, the lectures here are generally more mathematical, hands-on, and time-consuming. But don't worry, I keep the promise of stories and graphs over proofs. 
:::


```{mermaid}
%%| label: fig-mermaid
%%| fig-width: 9
%%| fig-cap: |
%%|   A mind map of lectures grouped by theme so you can navigate the study guide easier. See below all the topics, case-studies, references, and readings for each chapter or lecture.

flowchart TD

    U[Uncertainty] -- P. construction --> Comb[1. Combinatorics] --> PTr[2. Prob Triple, r.v.] --> RV[3. Distribution stories] --> B[4. Bayes & Conditioning]

    U -- estimator properties --> E[5. LLN, CLT, Properties] --> BV[6. Bias-Variance]

    U -- hypothesis testing --> NP[7. Neyman-Pearson] --> M1[/Module 1: A/B Testing/] --> Persp[8. Freq, Lik, Bayes] --> RC[9. Replication Crisis]

    style RV fill:#f7f5bc
    style B fill:#f7f5bc
    style NP fill:#f7f5bc

    style M1 fill:#ffb6c1
```



## Combinatorics. Sampling. Urn Models

There are several excellent courses which start from counting, and I think there are some extremely useful and practical things which you missed about combinatorics. Also, there is a way to learn you never have to remember stuff by heart.

- Multiplication rule
- Sampling with and without replacement. Ordered vs unordered
- Naive Probability
- A result about Bootsrap

::: {.callout-note}
## Birthday Paradox. Pigenhole Principle. Collision Problems

:::

## Probability Triple. Random Variables. Models

 | experiment, sample space, measure, population, estimand, estimators, golemns  | [Probability vs Statistics](https://johnkerl.org/doc/prbstat/prbstat.html), Kolmogorov, Garden Forking Paths |


If you understand and can explain the following ideas in a simple, yet rigorous way  -- you're ready for the journey. Otherwise, if it feels shaky, here are some readings:

- **Probability Triple** and **Random Variables** - a quasi formal introduction is written in [this chapter](https://course.economic-cybernetics.com/01_fundamentals/stat_foundations.html) of the course website. From my experience, not many students have this understanding after their probability theory classes.
- **Collectivity** ("physical" structure), **Statistical Population**, **Sample** - where defining the population is the contract for our experiment, and the sampling process is critical. It is a much more nuanced topic than it looks, explained well and in great detail [here](https://openintro-ims.netlify.app/data-design.html) and [here](https://crumplab.com/statistics/04-SamplesPopulations.html).
- **Parameter** (Estimand), **Estimator**, **Estimation/Statistic** - same resources as above [^4]
- Stories behnid distributions: $Bin(n, \theta), Pois(\lambda), Exp(\lambda), N(\mu, \sigma^2), \chi^2_k, t_k$. What about $Beta(a, b)$, $Gamma(k, \theta)$, and $Dirichlet(\bar{\theta})$ -- what are they good for?
  - Look at some [examples with simulations](https://mathstat.slu.edu/~speegle/_book/probchapter.html#simulationsprob) and [stories / applications with more math](https://drive.google.com/file/d/1VmkAAGOYCTORq1wxSQqy255qLJjTNvBI/view) from Joe Blitzstein.

[^4]: Although the perspective I take is Bayesian, I will take some time to cover and re-contextualize the Neyman-Pearson and Fisherian "frequentism".

## Stories behind distributions
**Binomial, Poisson**, Beta, Gamma. Stories behind distributions | PMF, PDF, CDF, Hypergeometric, Negative Binomial, $\chi^2_k$, mixtures, $t_k$, $N$, Weibull | couples showing up to safari, arrival times, basketball shots, hot hand |


## Conditioning and Bayes Rule

Likelihood Ratios | DAGs, Conditioning, Marginalization, Priors, Updating | Monty Hall, Simpsons' Paradox, Football Spreads, Medical testing |



We start simple, by modeling a single random variable $Y$, choosing the appropriate distribution for each phenomenon, a prior for the parameters, doing simulations  -- then sampling from the posterior with `pymc`, `numpyro`, and `bambi`.[^1]

[^1]: The R equivalents would be `stan` and `brms`, `rstanarm`. `bambi` and `brms` are a high-level API for most common models.

Limiting? Yes, as in reality we care about the relationship between random variables. However, we can get a lot of insight from thoughtful modeling the data generating process, which will serve as building blocks in more complicated and realistic models.

::: {.callout-note}
## Bayes Rule. Update your beliefs, often!

Any introduction to the subject will work out, a few excellent ones being Chapter 1/2 of [BDA3](http://www.stat.columbia.edu/~gelman/book/), Chapter 1/2 of [Bayes Rules](https://www.bayesrulesbook.com/chapter-2.html), and Chapter 1/2 of [Statistical Rethinking](https://xcelab.net/rm/statistical-rethinking/).[^2] If you prefer videos, enjoy the 3Blue1Brown [visual masterpiece](https://www.youtube.com/watch?v=HZGCoVF3YvM) on how to think like a Bayesian or [here](https://www.coursera.org/learn/statistical-inferences/lecture/R6nV5/bayesian-thinking).


- (BDA3, Ch1): **Football spreads**, that can be estimated from [data about matches](http://www.stat.columbia.edu/~gelman/book/data/football.asc). What is the probability that a team wins? Are experts right, on average?
  - If you're into betting and sports, can you replicate the analysis on other datasets? What are your options for data collection?
  - For brevity, I won't elaborate much from now on, how to take an use-case and example to its limit. **If you're passionate about a particular topic -- go for it!**
- (BDA3, Ch1): **Spelling correction**, based on [empirical frequencies](http://norvig.com/ngrams/) provided by Peter Norvig. As in the previous case-study, you will have to code it up and figure it out for yourself -- it is good for a warm-up, but challenging enough to keep you occupied.
- ([Probability 110](https://projects.iq.harvard.edu/stat110/home)): **Medical testing** for rare diseases, hypothetical example with code in my [course repository](https://github.com/Bizovi/decision-making/blob/main/playground/02_bayes.ipynb). We use the same idea to reason about how confident are we our code has no bugs.
  - If you remember the Covid-19 rapid tests and their confusion matrices printed on instructions, you could've applied the same idea!

For the simplest models, one approach of comparing different hypotheses, is Bayes Factors. However, these do not translate well in practice for more sophisticated, multilevel models. You can look in the following courses [here](https://www.coursera.org/learn/statistical-inferences/supplement/IPkZK/assignment-2-2-bayesian-statistics) and [here](https://www.coursera.org/learn/bayesian/home/week/3) for the theory and examples.
:::

[^2]: You will notice in the callouts that I point out where to read the theory -- for a conceptual understanding and to figure out the mathematical details

[Or maybe you're passionate about biology, where you could apply it for Mendelian genetics and think about the mystery of deadly genes persistence]{.aside}

We applied Bayes rule and got some insightful results in three totally different domains. However, we weren't doing neither statistics, nor inference -- but got into the right mindset. It is a good opportunity to brush off the shelves some computational and mathematical tools. Now it's time for full-luxury Bayes and the simplest cases of inference.


## LLNs, CLTs. Estimator properties

**CLT** and LLNs. Convergence types. Estimator properties | sample size, convergence in probability, distribution, almost-sure | The most dangerous equation, hackernoon ranking algo |


::: {.callout-tip}
## The most dangerous equation

I think that ["The most dangerous equation"](http://assets.press.princeton.edu/chapters/s8863.pdf) is a must read for anyone, not just practicing scientists and statisticians. You can see below two resources for the mathematical background of LLT, CLT, and some key properties of estimators.

- Central Limit Theorem (Kolmogorov), deMoivre - the most dangerous equation. Asymptotics. [the theorem and simulations here](https://mathstat.slu.edu/~speegle/_book/SimulationRV.html#centrallimittheorem)
- Estimator properties: Bias, Consistency, Efficiency - you can find an accessible explanation with R code in [openforecast](https://openforecast.org/sba/estimatesProperties.html)

Continuing on the reddit examples, there are some amazing case-studies in the "Calling Bullshit" website and book. One of them is exactly such a ranking problem: [best barbecue in the states](https://www.callingbullshit.org/case_studies/case_study_barbecue.html). I recommend you watch the whole playlist and work through the case studies: it is fun and an essential skill -- to call out the bullshit.
:::




## Bias-Variance. Fisher Information

**Bias-Variance**, Fisher Information, Rao-Cramer | Efficiency, Bias, James-Stein, curse of dimensionality | Bootstrap, simulations and visualizations |

Properties of Estimators | Bias-Variance, Fisher Information, Rao-Cramer | Relevance for ML, Deep Learning |


## Hypothesis testing. Neyman-Pearson

In order to make sense of frequentist hypothesis testing, I strongly recommend you read about the original idea of Neyman and Pearson (error control -- don't make a fool of yourself too often in the long run).

We will start from the first principles and will let go of mechanical application of procedures and conventions (p-values, $\alpha, \beta$, test choice). You should to be able to justify all the choices you make during the phase of experiment design, i.e. before running the experiment. This is certainly the most difficult lecture of the module.

- Picking a default action. Type I, II errors. How costly is each type of mistakes?
- Minimal **effect size** of interest, [Cohen's](https://rpsychologist.com/cohend/) $d$
- [Power Analysis](https://rpsychologist.com/d3/nhst/) and Sample Size justification. How surprising are significant findings under each hypothesis? Positive Predictive Value
- p-values [simulation](https://rpsychologist.com/pvalue/), [p-curve](https://rpsychologist.com/d3/pdist/) under $H_0, H_A$. 
- Confidence Intervals - first check out this [simulation](https://rpsychologist.com/d3/ci/).  Also [chapter 12](https://openintro-ims.netlify.app/foundations-bootstrapping.html), uses bootstrap to estimate those. Capture percent


::: {.column-margin}
In order to put everything together, there are four resources I can recommend:

- [T-test end to end](https://mathstat.slu.edu/~speegle/_book/HTCI.html)
- [here](https://www.huber.embl.de/msmb/06-chap.html)
- [here](https://statsthinking21.github.io/statsthinking21-core-site/ci-effect-size-power.html)
- improving your statistical inferences
:::

::: {.callout-note}
## Asking better questions

- Make riskier predictions: Non-Inferiority testing - [This visualization](https://rpsychologist.com/d3/equivalence/), Equivalence Testing, Range predictions
- Publication bias, open science, pre-registrations
- Telescope method and resource-based
- Type 3 errors (solving the wrong problem), [chapter14](https://openintro-ims.netlify.app/decerr.html)
- Read Werner Stahel's [Relevance](https://stat.ethz.ch/~stahel/relevance/stahel-relevance2103.pdf) paper and Gelman's Sign and Magnitude errors

:::

::: {.callout-tip}
## Choosing a model. Common statistical tests are linear models

Now, once you got the absolute basics of regression, it's important to realize that a lot of seemingly unrelated statistical tests in frequentist statistics are particular versions of linear models[^tests-lr].

- [pymc](https://www.pymc.io/projects/examples/en/latest/case_studies/BEST.html) - Krutsche fake data drug trial, t-test, [bambi](https://bambinos.github.io/bambi/notebooks/t-test.html). 
- [Common statistical tests are linear models](https://lindeloev.github.io/tests-as-linear/#1_the_simplicity_underlying_common_tests) and the [python port](https://www.georgeho.org/tests-as-linear/) 
- Choosing a statistical test: difference in proportions and means, test of $\sigma$, correlations
- Bootstrap and nonparametric tests
:::

[^tests-lr]: This will instantly systematize the zoo of tests, when to use them and what they do. DO NOT TRY TO MEMORIZE THEM! Instead, think very carefully about your use-case.



::: {.callout-note}
## A detour on the philosophy of science

- Understanding the philosophy of falsification and how it applies to hypothesis testing. [Week2 of this course](https://www.coursera.org/learn/improving-statistical-questions/lecture/j6Duu/lecture-2-1-falsifying-predictions-in-theory) has a great 20 minute explanation.
- Philosophy of science: Popper and Latakos, in this [lecture](https://www.youtube.com/watch?v=cgvKG_3Ck7Y)
- "The null is always false"
:::



## Frequentism vs Likelihood vs Bayes

Frequentism vs Likelihood vs Bayes | philosophical roots, agreements, weaknesses | The path of action vs devotion vs belief  |

Bootstrap and Nonparametrics | resampling, ECDF |  Kolmogorov-Smirnov |

When discussing hypothesis testing and experiment design, we can't avoid an overview of frequentist methods (path of action) and a discussion of the philosophy of science.

Path of action vs path of devotion vs path of belief

## Dead Salmon Experiment. Replication Crisis 

multiple testing, harking, snooping, publishing bias, open science, underpowered studies | Examination of controversies in medicine, psychology, and social science  |

Bootstrap, Multiple Testing | FDR, Bonferoni | Computer-age statistical inference |

Reproducibility vs Replication, Meta-Analysis

Ethics and Integrity

Simulation, 
