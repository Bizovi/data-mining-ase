---
format:
  html:
    toc-location: left
---

# Data Science in Business Context

Arguably, we live in a *volatile, uncertain, complex, and ambiguous* world that we have to understand in order to navigate it well. By "world", I mean the economy, society, environment, or any other complex system -- especially when human behavior is involved. It is reasonable to ask: wasn't it always the case, depending on how we define the terms, level of analysis, and point of view? 

I think it's a matter of scale and magnitude in VUCA dimensions, where an accelerating rate of change poses a great challenge to our capacity to adapt. Instead of an evolutionary or philosophical comment on why we need this field of data/decision science, I have two questions on my mind when it comes to living well or improving business outcomes: **what is true** and **how should I act**? [^general]

[^general]: This implies that we already framed the problem and figured out what we want to achieve, and that indeed we chose the right goals and objectives. Moreover, the questions of epistemiology and ethics are a never ending topic for discussion and enquiry.


:::: {.callout-tip}
## Decision Science: (not only) truth and action

Let's start from a business setting of an e-commerce, where we want to increase sales, customer satisfaction, and reduce costs. Imagine three scenarios, which neatly fall into the SWOT framework:

![*Source: [Kim Warren](https://strategydynamics.com/free/assets/The%20Dynamics%20of%20Strategy,%202016.pdf)* - Status Quo, Desired and Feared Trajectories](img/trajectories.png){width="60%"}



- We keep the status quo, doing everyting as before. What is the most likely trajectory of profits? Can we come up with an educated guess? If the trajectory looks good, that is our **strenghts** and compentencies contributing to it, if not, our **weakness**.
- A feared trajectory, that is, if our business is hit by a shock in supply chain, inflation, by competition or customer demand. It's the **threats**.
- A desired or aspirational trajectory. Is it reasonable and realistically achievable? If yes, what strategy and tactics should we implement, how sould we act? This is our **opportunity**.
::::

After this exercise, we defined more precisely where we stand, that is, quantify the current state of the firm. We framed the problem in terms of most relevant outcomes and we're in the process of figuring out what are the optimal goals to aim for. Obviously, we need a mechanism, measurements to know that we're on track and to recognize when we get there. Now, let's go back to our two questions and unpack them:

- **What is true?** In the most general sense, we're not asking for a mathematical and logical truth, but if it's plausible, probable, deserves serious consideration, is backed by evidence. I also mean that we understand the underlying causal mechanisms. Not least, an assessment of the current situation. The metaphor which I suggest for this is "seeing clearly", through the fog, illusions, and biases. [^scout]
- **How should I act?** What is plausible doesn't entirely answer this question, we can't derive an ought from is.[^hume] In business settings, I would think about action in terms of strategic alignment and optimisation.

The only missing pieces from this mental model that I argue for is tremendously important: **iteration** and **feedback**. Due to VUCA, we can't be sure our actions are optimal, or even that we're solving the right problem, therefore fast iteration and feedback ensures we're not taking too much risk, that we find out early about problems in our thinking and action, that we can change course to steer the ship back on track.

::: {.callout-note}
## Wait, this sounds familiar

Sounds an awflul lot like Cybernetics, doesn't it? Especially if we have the idea of a firm as a complex adaptive system as a pressuposition for this discussion.
:::

[^hume]: This is one of the most important and applicable philosophical ideas, introduced by David Hume: when one makes claims about what ought to be that are based solely on statements about what is.

[^scout]: Recommended reading: Scout Mindset by Julia Galef




<!-- You might've heard in the news that data scientist is the sexiest job of 21st century, that AI is going to take over, Deep Reinforcement Learning models are beating people at Dota and Chess, solving almost-impossible protein-folding problems. But what does it actually mean, if we step outside the hype/buzzwords, use a plain language, and apply these ideas in a more down-to-earth, day-to-day problems and challenges in businesses? -->

Now that it's more clear what I meant in the course introduction by improving business outcomes and bringing value to organizations, I didn't yet explain what does analytics, data science, machine learning, and AI do or are, and how to they fit in the picture we painted so far.


## How to navigate a lecture

You might've noticed that every lecture starts with a brief motivation, and then will have this kind of flowchart of arguments and ideas. It is supposed to be your guide and a roadmap, so that you don't get lost in various detours taken and keep the big picture in mind. 

My recommendation is that you go back to this diagram at the end of the reading or lecture, try to remember individual arguments and think for yourself how are they related, what is the golden thread connecting them. [^thread]

[^thread]: This is a course in which we look at the widest possible range of methods and models, without going into excruciating detail, as I don't know which ones will be useful for your particular applications and problems. The idea is to find the optimal tool for the job. 


```{mermaid}
%%| label: fig-mermaid
%%| fig-width: 9
%%| fig-cap: |
%%|   A mind map and roadmap of the ideas and topics in this lecture. 
%%|   It is designed to give you a wide context in which AI is used and misused.
%%|   The classroom version is designed to be participatory and conversational, 
%%|   but I will try to do my best to communicate that spirit in written form

flowchart TD
  DM[Decision-Making] --> SWOT[SWOT] --> St[Strategy]
  
  St --> Domains[Domains] -- case studies --> U[Uber / Rides] --> Ecom[E-Commerce]
  St --> BAW[Analyst's workflow] --> F[Why did you study those?]
  DM --> AI[What is AI?] --> Cy[Cybernetics Detour] 
  Cy --> Choice[Stats/ML/Analytics]

  F --> BYOP[Bring your own problem]


  style U fill:#f7f5bc
  style Ecom fill:#f7f5bc
  style F fill:#f7f5bc
```

We start with real-world applications of data science, define what AI, Cybernetics, Big Data, Analytics, Machine Learning mean. Then, we figure out why did we study all those mathy and computer science subjects during the Bachelor's degree. Next, we discuss what can go wrong while drawing conclusions from data -- culminating in a discussion of a problem of choice you're passionate about.

## What is Strategy?

Sounds like a naive question, but bad strategy is prevalent -- which comes from a misunderstanding about what is a strategy. I highly recommend [this article published by McKinsey](https://www.mckinsey.com/capabilities/strategy-and-corporate-finance/our-insights/the-perils-of-bad-strategy) -- we learn better from other's mistakes.

In short, it is not just **aspiration** towards goal or having a **vision** or setting a **target**. By analogy, remember the SMART criteria when you're setting goals. As true consultants, we can summarize the steps involved in developing a strategy in a matrix.

| Step | Outcome | Characteristics
|------|-------|------|
| Honest diagnosis | Identify obstacles |     Few critical, relevant aspects
| Guiding policy |  General approach to overcome | Focused on key aspects
| Coherent actions | Support policy with action plan   |  Coordinated and focused


Since strategy informs so much of decision-making, know your firm's strategy -- ask around, understand it, contribute to it. Call out bad strategy.



## Data Science in the Wild

At this point, you might get tired of me emphasizing the decision-making aspect of data science as the main point of why it is important. It's time we move from the general and abstact towards particular examples and applications in various industries. This will lead us to acknowledge how **prevalent** is AI (that we haven't fully defined yet) in firms, services and technologies we use every day. 

::: {.callout-important}
## During a lecture, I usually ask students
Can you give some examples of businesses, sevices, technologies, problems, and domains which you suspect do have AI/ML algorithms and models behind the scenes?

See below some very good answers and argumentations provided by the students last year, then we'll examine in more details one of them. Of course, there is always that one person, very passionate about sports or blockchain.
:::


::: {.callout-tip}
## Do some reverse engineering!

When reading this section, I want to get you into a mindset of the reverse engineer: step back and think deeply about products and services you use every day:

- Put yourself in the shoes of the business making those decisions and building those systems
- What were the goals, user/client needs?
- What was the firm's objective?
- What constraints did they hit? Why it was a difficult problem?
- What made it an appropriate use-case for ML, Statistics, and AI?
- What are some potential approaches they settled on?
- What would be a baseline, simple, naive solution?
:::



- **Dynamic pricing** in Bolt and Uber, which takes into account the weather, especially if it rains, peak hours: balancing demand and supply. It is at the intersection of ML and economic theory, as they are a platform or marketplace. Prices also change with respect to competitors, so we see aspects of an oligopoly behavior. [^uber_jack]  
- **Stock markets** and trading bots: at the intersection of economics, finance and AI. I would add the "good old" and boring portfolio management and venture capital enterprises.
- **Management consulting**: what market to enter, whether and how to build a new product (product development). Lots of use-cases in marketing and market research firms.
- **Medicine Applications**: developing new vaccines and drugs, aided by AI and designing clinical trials for novel treatments.
- **Banks and insurance**: risk management, predicting credit defaults on mortgages and business loans. Chatbots for customer support, for most frequent and simple questions.
- **Automotive**: routine tasks like automated parking, the race towards self-driving, autonomous or semi-autonomous cars, safety warnings. Predictive maintainance is tackling a problem where they leverage predictions to replace risky parts before they go out of function.
- Liverpool F.C. won a title, and a key part of their success was leveraging AI and ML to discover new tactis on the field with the highest payoffs. [^liverpool]
- **NBA** teams invested a lot in the data infrastructure and decision-making capabilities: LA Lakers found the best player at the moment for a particular position they were lacking and would play well along with the team. Rockets won the regular championship divison by going all in on the 3-point shot.[^rockets] Golden State Warriors simply revolutionised basketball with data, before everyone else was doing it -- giving them a competitive edge. [^nba]

[^uber_jack]: When it doesn't work out -- I'm pretty upset at their data scientists and domain experts. Here is where ethical issues creep up: jacking up prices, monopolies, drivers struggling to make a living wage.

[^liverpool]: TODO: Reference article and maybe dataset for more details
[^nba]: Check out the following [video by The Economist](https://youtu.be/oUvvfHkXyOA) on how data transformed the NBA. For more details on the statistical methodology, I enjoyed an youtube channel called Thinking Basketball and their [playlist](https://www.youtube.com/watch?v=pznoCFs7XZg&list=PLtzZl14BrKjTJZdubjNEY5jU0fGOiy51x) about the statistical methodology.
[^rockets]: [Moreyball: The Houston Rockets and Analytics](https://d3.harvard.edu/platform-digit/submission/moreyball-the-houston-rockets-and-analytics/) -- an article in Harvard's MBA Digital Innovation

In all of the examples above, those businesses and systems do have to make decisions, under uncertainty from multiple sources, trying to solve complex problems at a large scale, which would be impossible to do manually even with an army of employees. 

I would like to add a few more examples, from an insider and practitioner's perspective, which might not be as impressive and a bit routine, but no less important. Keep in mind, that if at a closer look, the service seems to do something relatively intelligent very fast, specialized AI might be involved behind the scenes.

- **Demand Planning**: How many SKUs (items) should I order for manufacturing, to satisfy the demand (that last item on the shelf, minimizing lost sales) and to minimize excess inventory.
- **Logistics** and **Supply Chain**: routing, distribution center operations and automations for order fulfillment, return management
- **Recommender systems** for music, videos, books, products, news in social media, services, platforms, and e-commerces like facebook, instagram, tiktok, youtube, spotify, amazon, emag. You can find recommendations in surprising places, like google maps.
- **Programmatic Advertisement**: finding best placement for ads on various platforms, right now dominated by meta and google

:::{.callout-tip}
## Classroom Case Studies for a Deeper Understanding

We will explore some challenges and applications from this list in a series of case studies and labs. The idea is to improve our ability to identify opportunities and formulate problems from the point of view of an organisation, such that we can match those with the methods, models and algorithms discussed in the course. 

I'll have to introduce a lot of new concepts when the language we developed so far will turn out to be insufficient to talk about and understand what's happening inside these firms. Thus, each case study is an opportunity to play around with a novel idea. [^skip-to-cases]

- In the first deep-dive, we will look at Uber and Bolt, with publicly available information, trying to figure out what do their data scientists do. 
- Then, we will look at the lingerie e-commerce where I work at, AdoreMe and a different set of problems we're facing.
:::

[^skip-to-cases]: If you have a pretty good idea about what is AI, Analytics, ML, Deep Learning, Big Data, Causal Inference and when to use one approach or another, feel free to skip the history and terminology and go straight to the case studies.




## What is AI, Data Science, Cybernetics? 


It's undeniable that there is a lot of excitement when it comes to AI, ML, and data science -- to the point of calling it the sexiest job of 21st century. Data science is an umbrella term, with interdisciplinary at its core, drawing inspiration from multiple fields, sets of tools, practices, methods and it continuously evolves. [^questions]  It is designed to help us tackle increasingly more complicated problems at a large scale. There is also a reasonable worry about ways in which these systems can go wrong or awry.

You will often see a Venn diagram where data science sits at the intersection of mathematics -- statistics, computer science -- software engineering, and domain knowledge. I think this is not sufficient to characterise data science, therefore, will try to elaborate **what** it does, and **how** (which is as important). 

[^questions]: There are many questions still unanswered: How does this landscape of Data Science look like? What are the roles and jobs? What is the process for building smarter, data-driven software systems; drawing more reliable inferences and conclusions from data and theory? How does a day in data scientist's life look like?


::: {.callout-important}
## AI in a Nutshell
For all pragmatic intents and purposes, especially in businesses, AI is about **Decision-Making under Uncertainty at Scale** [^cassie-ai-def]. 

One important keyword here is `uncertainty`, as there is no point in building AI solutions based on complex models if we don't have uncertainty. We have to be able to change our mind and actions in the face of evidence.

On the other hand, `scale` is the reason ML and Deep Learning is so powerful, because you can take lots of small decisions in an automated way, with little curation or guidance from humans. This is why many traditionally "paperwork" industries like legal and accounting embrace digitalisation and automation now. 
:::

Ultimately, why would I build a system which predicts demand for products in a direct-to-consumer ecommerce like Allbirds, Macy's, or AdoreMe? Either in a marketplace like Emag or Amazon? Why would I try to find out the factors which contribute to a successful advertisement?


::: {.callout-tip}
## Here are some answers from students

- In order to **allocate resources** to the stuff which generates growth and profit. Avoid being scattered around (which I would call bad strategy), resulting in costs over targets and inefficiency.
- In short, we attempt to allocate resources and efforts **efficiently**.
- We can view **information as a competitive advantage**, anticipating and predicting so that we can plan and prepare, outperform competitors.
:::

When we talk about uncertainty, it's important to recognize its sources: [^uncertainty-sources] one coming from incomplete information, that we always work with samples in one way or another. For example, even if at a certain point in time we might have real-time data, everything evolves and quickly becomes outdated. Everything is in a state of flux and change. Even in the current state, we don't know for sure where we stand -- sometimes, in economics, this problem is called `nowcasting`. When talking about the future, making a good prediction is one of the most difficult things. 

For example, who would've predicted the pandemic and all its implications on the supply chain and society? It's important to note the difference between this kind of **black swan events** and the irreducible, fundamental uncertainty, which can't be captured by any explanatory factors.

In a happy case, we can quantify and reduce it by conditioning the model, that is, joint distribution of random variables with a given structure, on data. That would result in inferences and evidence with respect to our hypothesis and model of the world.[^generalization] At the very least we can try to quantify how uncertain are we. 

So, we still have to make decisions. Those have to have a level of **robustness** and resilience to shocks, in the face of uncertainty. I would go even further, to suggest that we should **aim for antifragility**, meaning, the system improves after a shock or negative event, but that is very hard to implement and operationalize, therefore, it falls outside the scope of this course -- to the realm of systems' design. 


[^uncertainty-sources]: We will talk more formally about sources of uncertainty in the next lecture, while reviewing the [fundamentals of statistics](stat_foundations.qmd#sources-of-uncertainty).

[^generalization]: We want to say something intelligent about the population, technically, to generalize. However, there is ambiguity, as objectives and the meaning/semantics of data fields are not always mathematically clear or without conflict. 

::: {.callout-warning}
## When you don't need AI and Statistics

As a though experiment, imagine we have an equation or program, with well-defined rules, which perfectly predicts the price on stock markets, or perfectly predicts how many items will a client buy and how she will respond if we change the price (an intervention). We won't need machine learning, causal inference, or AI there.

Of course, we don't have that kind of program. It's only somewhat true in cases when we have a well-tested theory, which stood the test of time and went through the scientific process to become the best theory with respect to all others. For example newtonian physics, relativity, quantum mechanics, evolution. 
:::

However, when we talk about human behavior, we should resist the temptation and arrogance to say that we have a well-defined theory, be it normative or positive. Our preferences change, and we can "decide" in which direction they change or persist. 

Regardless of the business we work at or own, the place in the value chain, we'll have to deal with human behavior: customers, employees, decision-makers, engineers. We need other kind of tools to infer perceptible regularities and patterns in their behavior. We will be forced in one way or another to learn from data and observation.

::: {.callout-tip}

## A model is a simplified representation of reality

We need models to make sense of the world around us, because it is so complex and uncomprehensible if we are to represent it faithfully in a simulation. Therefore, we focus on relevant, interestig, essential aspects to us, we simplify by baking in domain knowledge, assumptions, and data into the models and algorithms. 

So, we can collect data, apply algorithms to train models, in order to make inferences about some relevant quantities. That will help us in making evidence-based decisions which gets us closer to our objective in an efficient way.  
::: 

::: {.callout-important}
## Weak AI is Domain-Specific 

By now, you probably figured out that we're not talking about General AI, trying to surpass human intelligence in general reasoning and problem-solving. Thus, we're talking about weak or specialized AI, which depends very much on the domain.

AI in an a fashion e-commerce, like AdoreMe, where we sell lingerie, will have a very different flavor from the tools and methods used in genomics, medicine, social science or psychology. 

Despite the fact that there are a lot of shared fundamentals, when it comes to the principles of building models, it is not straightforward to take something which works in one domain and apply it in another. Significant tweaks and adaptations are needed, which are dependent on the specificities of that domain.  

The good news is that when these transdisciplinary groups of people work together and successfully adapt a method, it is often a breakthrough in the field borrowing the theory and technology.
:::


### Cybernetics is what we call AI

At this point we have a working definition of Weak AI. At a first glance it might be hard to see what does it have in common with Cybernetics and its study of Complex Adaptive Systems.

I'm not trying to equivocate those two, but argue that weak AI is how Cybernetics evolved and is mostly used in practice now. I will give a definition from P. Novikov, which I found tremendously useful, then explain it. Can you spot the parallels of "decision-making under uncertainty at scale" in this definition? 

::: {.callout-important}
## A better definition of Cybernetics
The science of **general regularities** of **control** and **information processing** in animal, machine and human (socitey)
:::


::: {.callout-tip}
## Unpacking this dense/abstract definition

- **Control** means **goal-directedness**, the ability to reach the goals and objectives by taking action and stirring the system towards a trajectory. The objective can also be perserving the structural-functional organization of the system itself, an **autopoesis**.
- **Information Processing** could be pattern recoginition, perception, how you understand and model the world, what inferences do you draw, what "data inputs" are used
- **General regularities** means what is true and plausible of control and information processing across fields and a variety of complex systems, not only in particular cases.
- Animal refers to applications in biology, machine -- in engineering, and human -- in our society and behavior.

In economic cybernetics, we're concerned with economics, society and human behavior, rather than engineering, biology, or natural science applications.
:::

To explain how Cybernetics evolved into Weak AI, there is a conglomeration of fields which went a bit out of fashion and favor: Game Theory, General Systems' Theory, Agent-Based Modeling, Systems' Dynamics, Complexity and Chaos, Evolutionary Algorithms. This stuff is fascinating and inspired many other breakthroughs, but it is extremely difficult to implement in practice.

So, we kind of settled on a more pragmatic set of tools, which is dominated by pattern recognition and optimisation, in one form or another trying to learn from data (ML, DL, Causality) and act optimally (Dynamic Programming, Reinforcement Learning). .

Wait. What's going on here? Am I saying that we did a bachelor's degree in AI under the term of Economic Cybernetics? For me, personally, after having this epiphany -- everything I studied makes so much more sense in retrospective.

::: {.callout-tip}
## The meaning of AI changed in the meanwhile

You can make sense of the terminology and general confusion of terms, by reading M. I. Jordan's brilliant article [^jordan-ai], which tells the history of "AI" and how this confusion arose. He also points out how many of the claims in the field, as of today are a stretch (i.e. the revolution hasn't happened yet) [^jordan-revolution].

I highly encourage you to read the articles by M. Jordan, but until then, here are a few ways people understand AI:

- Cybernetics and **Weak AI**, which we discussed before
- **General AI** is a titanic project. It interweaves with Philosophy, Cognitive Science, in order to understand what makes us intelligent and conscious. On the other hand, trying to build general-purpose problem solving machines.
- Symbolic AI, is still relevant in a few niches, especially in automated proofs and logical reasoning.
- Augmentative AI, like VR, augmenting human capabilities, human-machine interactions
:::

In practice, if you're a data/business analyst, ML/data engineer, data scientist, statistician, product manager -- Cybernetics is a way of thinking in systems and formulate problems well. When it comes to implementation, we mostly use data and the tools, models, methods discussed in this course.



## Analytics, ML or Statistics?

At this point, you should have a pretty good idea why data science is important, what are some possible applications and domains, what does it do and is concerned about. It is the motivation, real-world use-cases, and conceptual understanding that I promised at the beginning of the course.

Disentangling the ambiguity around AI was one of the most difficult aspects of the course to articulate. Now, it's time to transition to a lower level of analysis (inside data science, not outside it), break down the landscape into manageable chunks and develop our toolbox, in which we learn how to formulate problems well and match them with existing models, methods, and technologies.

One of the first tools I want to introduce, is distinguishing three ways of thinking, which have to work harmoniously together, in order for a data science project to be successful:

* **Analytics and Data Mining**, where the main goal is formulating better research questions and hypotheses, that is, get **inspiration**, find interesting and relevant patterns and relationships in massive datasets
* **Machine Learning**, as a way to use training algorithms to go automatically from experience (data) to expertise (a program or recipe for prediction). Put in other words, learning from data, finding invariants, patterns which generalize beyond our sample and training data.
* **Causal Inference** [^caus-stats] for making decisions with high stakes, where we have to understand the causal processes of the system in order to intervene optimally. It enables greater transparency, reliability, and rigor in the inferences and conclusions drawn.

[^caus-stats]: I find that statistics is not the right term here, as it is too broad, especially recently when the lines between ML and Stats are getting more blurry, as one adopts methods from other. 

![*Source: xkcd;* Which one to choose and when? We will have some unlearning to do here, as much of the previous courses were in one way or another focused on analytics. Even in statistics or econometrics, there is little from the field of causality, which is necessary to apply it to real-world challenges. On the other hand, you applied ML methods, but in my opinion, without understanding what ML is, without a rigorous process which would ensure we don't overfit or snoop the data, without a clear plan of how to deploy it to production and make decisions based on those predictions.](img/ds-adventure.png "Analysis"){width="90%"}

::: {.callout-important}
## The art of formulating a hypothesis

In many intro to statistics or science courses, we take for granted the hypothesis, it is often our starting point. How does one come up with a business or scientific hypothesis with makes sense, is reasonable, plausible, deserves serious consideration? Since there are an infinity of possible ones, how do we pick the most relevant?

I argue, it is an art which requires a kind of **intuition**, **sensibility**, and **attunement** to the problem. In my opinion, it is the most underrated aspect of scientific enquiry and process: a good problem formulation often gets us halfway towards a solution.

In this course we focus on data mining and analytics as a way to get inspiration for good questions to ask and hypotheses to formulate. However, in anthropology or evolutionary biology, it could be done by careful observation of the behavior, coupled with a deep understanding of the field, existing theories and their shortcomings and inconsistencies. Often, these hypotheses follow as a consequence from the theory itself.
:::

If we don't have to make decisions and want to find interesting patterns in data, to inform our future questions, we have lots of methods for exploratory data analysis -- from visualization (manual) to clustering (automated) and model-driven exploration. Sometimes, we just want to monitor and display the facts and current state of a business on a dashboard -- this is why your previous class was on BI (Business Intelligence).

Then, in the decision-making processs, these questions and hypotheses can be communicated to statisticians and decision-makers, so that they have a clearer direction and more promising candidates to experiment with. This doesn't mean that what we found the causal process which makes some clients more profitable than others, when we notice a difference between groups or clusters of clients.


If we do have to make a few, high-stakes, strategic decisions of major importance to business outcomes and user experience, that means we need some rigorous statistics. For example, how to price the products, whether to enter a new market, what products to develop, how to allocate advertisement spending across different platforms, whether to deploy a new recommender system. We will discuss at length what can go wrong in drawing conclusions from data alone (with analytics or ML), and how that can backfire spectacularly.


If we have to make lots of decisions at scale and high frequency, for example -- doing demand forecasting and inventory optimization for 100k product SKUs, it cannot be done manually or with carefully designed experiments. In this case, an appropriate choice would be to learn from data and get predictions as reliable as possible. Keep in mind, that we will have to be very careful when defining what the model is optimizing for -- it has to be aligned with business objectives.

Why ML, since we put so much emphasis onto scientific rigor and trying to infer the causal processes? Sometimes -- you don't have a theory. For example, in recommender systems it's just too complicated, with so many heterogenous users and items, each with their specific preferences and idiosyncracies.



::: {.callout-tip}
## Why not use all at various stages of a project?

It is not a debate of which one is better: ML vs Stats vs Analytics. One has to cycle through these approaches, gain greater understanding, experience, and skill in order to use the appropriate tools in the right context. 

I recommend the following 4-part presentation [^cassie-mfml] by Cassie Kozyrkov, so that you get a good idea of how AI fits into organization and decision-making process. I recommend following her and, basically reading everything she has written on medium.
:::

Pay close attention to the process of developing data-driven products [^cassie-steps] and what are the prerequisites for an AI project to be successful (or doomed from the very start). It is important not to skip the relevant steps, understand the roles of people involved: from decision-makers, to statisticians, and data engineers. A good blueprint [^pair] for thinking about how to define and plan an AI project is given by Google's PAIR (People and AI Research group). We will discuss all of this in detail during our next lectures and case studies.


::: {.callout-important}
## Are we in the business of ML?

The next two questions are tremendously important and will prevent you from embarking on an AI project which is doomed from the start:

- Is there a value proposition for AI? In other words, is there an underlying pattern to be discovered?
- Do I have the (necessary and relevant) data?

If yes and yes, we MIGHT be in business! But we shall not forget about the pragmatic aspects: is it feasible to be done with a small team, without a huge investment? What is the simplest way we can solve it? Are we solving the right problem? Are we making the job of people in the firm easier and more efficient?
:::

Make no mistake, the data science field is fascinating and full of exciting applications, but as you well know from statistics, there are numerous pitfalls we can fall into. I think it is useful to demistify AI and get humble, down to earth about what it can and can't do -- its power, but also the limitations:

- Just take a look at how many AI tools have been built to catch covid, and none helped [^mit-ai-covid]
- One part of the problem is the mismatch between the real/business problem and objectives, versus what models optimize for. Vincent Warmerdam brilliantly explains it in "The profession of solving the wrong problem"[^war-wrong-problem] and "How to constrain artificial stupidity" [^war-stupidity].


::: {.callout-warning}
## Split your damn data! (on data snooping)

Since we're engaging in the business of data mining and analytics at one point or another of the project, we have to be extra careful. Intuitively, you understand that discovering hypotheses and testing them on the same set of data is a bad idea, because we'll get an overly confident estimation of how good it is. 

However, sometimes, we don't shy away from doing an exploratory data analysis, finding relevant and predictive features for our target variable by trying out a few models. Next day, we forget about this, having the conclusions crystalized in our mind, and apply a new, final model ... on the same data. Often we get away with this, but it is as bad, meaning equivalent to the first case -- we contaminated the data with our mining.

So, before we get into the nuances of model validation, selection, and experiment design, get into the habit of always splitting your data. Give that test dataset to a friend, locked under a key and don't let her give you that data, until you have your final model to be deployed and used for decisions.
:::

Why go through all of that pain to critique our own model with such a vigor? The answer is simple -- if it passes this rigorous critique, it has greater chance of finding a real/causal pattern and generalize to examples outside our sample. 

## Business Analysts' Workflow

This is a lot to take in! But there is one more thing to explore -- a brilliant idea from a  course by Dr. Adam Fleischhacker [^business-analytics], which has a very similar philosophy, but is much more established and thought out, with many practical examples. Here is what he has to say in the course intro:

[^business-analytics]: Adam Fleischhacker - [Introduction to Business Analytics](https://www.causact.com/): Intro to Bayesian Business Analytics in the R Ecosystem

> "You will translate real-world scenarios into both mathematical and computational representations that yield actionable insight. You will then take that insight back to the real-world to persuade stakeholders to alter and improve their real-world decisions."

Dr. Fleischhacker makes an illuminating distinction between the **business analyst's workflow** and a machine learning workflow, and sets up the normative criteria which make it successful. In our course, his workflow falls under the discussions related to **causal inference**. One interesting thing to note, is the convergence in the approach of an extremely diverse set of people: Cassie Kozyrkov, Vincent Warmerdam, Adam Fleischhacker, Richard McElreath, Andrew Ng -- all coming from different backgrounds and activating in different environments and domains.

![*Source: causact.com*; "(The workflow) starts with strategy, expertise, and data as inputs and results in the business analyst leading their firms to act on value-adding insights"](img/analyst-workflow.png "Analysis"){width="90%"}

Let's briefly review those normative criteria of this workflow. It might be a confirmation bias on my part, but the fact that these are present in the current course in one way or another, means I stumbled upon them by trial-and-error and painful mistakes:

- **Outcome-focused**: What is the point of fancy models, if we don't achieve good or desired outcomes? If I was implying it so far, for the rest of the course we'll ask this explicitly every time we tackle a business problem.
- **Strategically-aligned**: *"Not all outcomes are created equal. Companies seeking to capture market share might increase expenses to aid market capture. Companies seeking to be cost leaders might leave some customers unsatisifed to keep expenses low. So a one-size-fits-all approach to defining good outcomes is ill-advised."*
- **Action-oriented**: We insisted so much on insights influencing, driving actions and decisions that there is little to add here. The remaining question is how can we communicate and articulate it well to convince decision-makers and stakeholders.
- **Computationally Rigorous**: Refers to the know-how, the engineering in the trenches. Even though we'll spend most of the time in the frequentist land -- I think the future is at the intersection of Causality and Bayesian Inference. 
  - Taking it one step further, this kind of workflow should be reproducible and (mostly) automated. This is why we'll explore an ecosystem of software engineering tools and practices in the labs. 
  - Ideally, given in the hands of our clients/users in form of a full stack data app. This is where we take off our consulting hat and start building software products.


This is in contrast with a predictive, machine learning workflow, which we called before "workhorse models", a "hammer" for which everything is a nail. We got a taste of its power and limitations, and tried to articulate which are appropriate applications for ML. This course gives equal attention to ML and Causality, due to the prevalence of use-cases from which we can learn from data to make tons of decisions at scale and high frequency. 

![*Source: causact.com*; "The machine learning analyst transforms historical data with known outcomes into future outcome predictions."](img/ml-workflow.png "Analysis"){width="90%"}



<!-- Data Science Context, in Business, Interdisciplinarity --->
[^pragmatic-ai-gcp]: M. Bizovi - [Pragmatic AI in Google Cloud Platform](https://www.youtube.com/watch?v=02NPR_nDaxQ)
[^jordan-ai]: K. Pretz - [Stop Calling Everything AI](https://spectrum-ieee-org.cdn.ampproject.org/c/s/spectrum.ieee.org/amp/stop-calling-everything-ai-machinelearning-pioneer-says-2652904044), Machine-Learning Pioneer Says 
[^jordan-revolution]:  M. Jordan - [Artificial  Intelligence](https://hdsr.mitpress.mit.edu/pub/wot7mkc1/release/9): The Revolution Hasn’t Happened Yet
[^cassie-mfml]: C.Kozyrkov - [Making Friends with Machine Learning](https://youtube.com/playlist?list=PLRKtJ4IpxJpDxl0NTvNYQWKCYzHNuy2xG)
[^cassie-ref]: C. Kozyrkov (Chief Decision Scientist | Google) - https://kozyrkov.medium.com/ 
[^cassie-ai-def]: C. Kozyrkov - [AI is decision-making at scale](https://www.youtube.com/watch?v=bCjMhZZYlP4)
[^cassie-steps]: C.Kozyrkov - [12 Steps to Applied AI](https://medium.com/swlh/12-steps-to-applied-ai-2fdad7fdcdf3)
[^pair]: People and AI Research | Google - [Guidebook](https://pair.withgoogle.com/guidebook/)
[^mit-ai-covid]: W.Heaven - [Hundreds of AI tools have been built to catch covid. None of them helped.](https://www.technologyreview.com/2021/07/30/1030329/machine-learning-ai-failed-covid-hospital-diagnosis-pandemic/)
[^war-wrong-problem]:  V. Warmerdam - [The profession of solving the wrong problem](https://www.youtube.com/watch?v=kYMfE9u-lMo)
[^war-stupidity]: V. Warmerdam - [How to Constrain Artificial Stupidity](https://www.youtube.com/watch?v=Z8MEFI7ZJlA)

[^37]: Thoen - [Agile Data Science with R](https://edwinth.github.io/ADSwR/index.html)
